{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Depth Network\n",
    "AhmadReza Nopoush\n",
    "\n",
    " id:  610301194\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at the begining we produce the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Xs , y = make_gaussian_quantiles(n_samples=300,n_classes=2, n_features=8, random_state=42)\n",
    "X_train , X_test , y_train , y_test = train_test_split(Xs,y, test_size=0.2, random_state=42)\n",
    "y_train = np.reshape(y_train,newshape=(240,1))\n",
    "y_test = np.reshape(y_test,newshape=(60,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the activation function and their deriativision wich used in network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(Z) -> float:\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def RelU(Z) -> float:\n",
    "    return np.maximum(0, Z)\n",
    "    \n",
    "def deriative_of_RelU(Z) -> int:\n",
    "    return Z > 0\n",
    "    \n",
    "def deriative_of_Sigmoid(Z) -> float:\n",
    "    s = Sigmoid(Z)\n",
    "    return s*(1-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to the formulas we have, we define a \"ForwardPropagation\" function.\n",
    "\n",
    "$$\n",
    "Z_1 = W_1 \\times X^T \n",
    "$$\n",
    "$$ \n",
    "A_1 = \\text{ReLU}(Z_1) \n",
    "$$\n",
    "$$ \n",
    "Z_2 = W_2 \\times A_1 \n",
    "$$\n",
    "$$ \n",
    "A_2 = \\sigma(Z_2) = Y_{\\text{pred}} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X, We1, b1, We2, b2,threshold=0.5):\n",
    "    Zi1 = np.dot(We1, X.T) + b1\n",
    "    Ay1 = RelU(Zi1)\n",
    "    Zi2 = np.dot(We2, Ay1) + b2\n",
    "    Ay2 = Sigmoid(Zi2)\n",
    "    return (Ay2 >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should implement backward propagation using mathematic formulas we have below.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{cost}}{\\partial W_2} = \\frac{\\partial \\text{cost}}{\\partial A_2} \\times \\frac{\\partial A_2}{\\partial Z_2} \\times \\frac{\\partial Z_2}{\\partial W_2} = \\left(-\\frac{2}{n}(Y_{\\text{true}} - A_2) \\odot A_2 \\odot (1 - A_2)\\right) \\times A_1^T \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{cost}}{\\partial W_1} = \\frac{\\partial \\text{cost}}{\\partial A_2} \\times \\frac{\\partial A_2}{\\partial Z_2} \\times \\frac{\\partial Z_2}{\\partial A_1} \\times \\frac{\\partial A_1}{\\partial Z_1} \\times \\frac{\\partial Z_1}{\\partial W_1} = \\left(\\left(\\left(-\\frac{2}{n}(Y_{\\text{true}} - A_2) \\odot A_2 \\odot (1 - A_2)\\right)^T \\times W_2\\right) \\odot \\frac{\\partial A_1}{\\partial Z_1}\\right) \\times X \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BackPropagation(Xs, Yp, Zi1, Ay1, Zi2, Ay2, We1, We2):\n",
    "    n = len(Xs)\n",
    "    \n",
    "    dZ2 = (2/n)*(Ay2 - Yp.T)*deriative_of_Sigmoid(Ay2)\n",
    "    dW2 = np.dot(dZ2, Ay1.T)\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    dA1 = np.dot(We2.T, dZ2)\n",
    "    dZ1 = dA1 * deriative_of_RelU(Zi1)\n",
    "    dW1 = np.dot(dZ1, Xs)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the updating rules is obvieous. we defined the **Update** function according to formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, the implementation of MSE; our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the **Train** function, to train our model based on our data. This function get the paramethers:\n",
    "1. **X_train**: the list of 6D-arrays wich contains the train dataset.\n",
    "2. **Y_train**: the lable of train dataset.\n",
    "3. **hidden**: the number of neurons in hidden layer.\n",
    "4. **learning_rate**\n",
    "5. **epochs**: number of iterations to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(X_train, Y_train, hidden:int, learning_rate:float, epochs:int):\n",
    "    #count of input neurons:\n",
    "    inp = len(X_train[0])\n",
    "    \n",
    "    #count of output neurons:\n",
    "    output = 1\n",
    "\n",
    "    #initializing paramethers:\n",
    "    Weight1 = np.random.randn(hidden, inp) * 0.01\n",
    "    w=Weight1\n",
    "    b1 = np.zeros((hidden, 1))\n",
    "    Weight2 = np.random.randn(output, hidden) * 0.01\n",
    "    b2 = np.zeros((output, 1))\n",
    "    \n",
    "    #for each epoch do:\n",
    "    for epx in range(epochs):\n",
    "        #generate solution and weights\n",
    "        Zi1 = np.dot(Weight1, X_train.T) + b1\n",
    "        Aa1 = RelU(Zi1)\n",
    "        Zi2 = np.dot(Weight2, Aa1) + b2\n",
    "        Ay2 = Sigmoid(Zi2)\n",
    "        Ay2 = (Ay2 >= 0.5).astype(int)\n",
    "                        \n",
    "        #calculate the MSE\n",
    "        loss = MSE(Y_train, Ay2.T)\n",
    "        \n",
    "        #back propagation\n",
    "        dW1, db1, dW2, db2 = BackPropagation(X_train, Y_train, Zi1, Aa1, Zi2, Ay2, Weight1, Weight2)\n",
    "        \n",
    "        #update weights\n",
    "        We1, bi1, We2, bi2 = Update(Weight1, b1, Weight2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "        Weight1 = We1\n",
    "        Weight2 = We2\n",
    "        b1,b2 = bi1,bi2\n",
    "        \n",
    "        #print loss every 10 epochs\n",
    "        if epx % 50 == 0:\n",
    "            print(\"Epoch \",epx,\": Training loss = \", loss)\n",
    "    \n",
    "    #return weights\n",
    "    return Weight1, b1, Weight2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at last, we test the model we implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.5\n",
      "Epoch  50 : Training loss =  0.44166666666666665\n",
      "Epoch  100 : Training loss =  0.35\n",
      "Epoch  150 : Training loss =  0.25833333333333336\n",
      "Epoch  200 : Training loss =  0.20833333333333334\n",
      "Epoch  250 : Training loss =  0.12916666666666668\n",
      "Epoch  300 : Training loss =  0.13333333333333333\n",
      "Epoch  350 : Training loss =  0.1125\n",
      "Epoch  400 : Training loss =  0.08333333333333333\n",
      "Epoch  450 : Training loss =  0.04583333333333333\n",
      "Epoch  500 : Training loss =  0.0375\n",
      "Epoch  550 : Training loss =  0.04583333333333333\n",
      "Epoch  600 : Training loss =  0.008333333333333333\n",
      "Epoch  650 : Training loss =  0.0125\n",
      "Epoch  700 : Training loss =  0.0\n",
      "Epoch  750 : Training loss =  0.0\n",
      "Epoch  800 : Training loss =  0.0\n",
      "Epoch  850 : Training loss =  0.0\n",
      "Epoch  900 : Training loss =  0.0\n",
      "Epoch  950 : Training loss =  0.0\n",
      "Test Loss: 0.05\n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.475\n",
      "Epoch  50 : Training loss =  0.3416666666666667\n",
      "Epoch  100 : Training loss =  0.24583333333333332\n",
      "Epoch  150 : Training loss =  0.20416666666666666\n",
      "Epoch  200 : Training loss =  0.16666666666666666\n",
      "Epoch  250 : Training loss =  0.125\n",
      "Epoch  300 : Training loss =  0.09166666666666666\n",
      "Epoch  350 : Training loss =  0.0625\n",
      "Epoch  400 : Training loss =  0.08333333333333333\n",
      "Epoch  450 : Training loss =  0.06666666666666667\n",
      "Test Loss: 0.13333333333333333\n",
      "Test Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.49166666666666664\n",
      "Epoch  50 : Training loss =  0.3541666666666667\n",
      "Test Loss: 0.26666666666666666\n",
      "Test Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion ####\n",
    "By increasing the number of Epochs, the model fits better with the data. When the Epochs reach 1000, the network completely matches the dataset and the MSE becomes zero. So the number of Epochs more than 1000 will not be meaningful. To check the effect of the learning coefficient, we consider the **Epochs = 500**,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.48333333333333334\n",
      "Epoch  50 : Training loss =  0.5458333333333333\n",
      "Epoch  100 : Training loss =  0.5333333333333333\n",
      "Epoch  150 : Training loss =  0.5208333333333334\n",
      "Epoch  200 : Training loss =  0.525\n",
      "Epoch  250 : Training loss =  0.5291666666666667\n",
      "Epoch  300 : Training loss =  0.5083333333333333\n",
      "Epoch  350 : Training loss =  0.5041666666666667\n",
      "Epoch  400 : Training loss =  0.49583333333333335\n",
      "Epoch  450 : Training loss =  0.49583333333333335\n",
      "Test Loss: 0.6333333333333333\n",
      "Test Accuracy: 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.4791666666666667\n",
      "Epoch  50 : Training loss =  0.4708333333333333\n",
      "Epoch  100 : Training loss =  0.4125\n",
      "Epoch  150 : Training loss =  0.32083333333333336\n",
      "Epoch  200 : Training loss =  0.2833333333333333\n",
      "Epoch  250 : Training loss =  0.2791666666666667\n",
      "Epoch  300 : Training loss =  0.26666666666666666\n",
      "Epoch  350 : Training loss =  0.23333333333333334\n",
      "Epoch  400 : Training loss =  0.2\n",
      "Epoch  450 : Training loss =  0.15416666666666667\n",
      "Test Loss: 0.3\n",
      "Test Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.005\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.44166666666666665\n",
      "Epoch  50 : Training loss =  0.35\n",
      "Epoch  100 : Training loss =  0.2375\n",
      "Epoch  150 : Training loss =  0.1625\n",
      "Epoch  200 : Training loss =  0.1125\n",
      "Epoch  250 : Training loss =  0.09583333333333334\n",
      "Epoch  300 : Training loss =  0.11666666666666667\n",
      "Epoch  350 : Training loss =  0.07916666666666666\n",
      "Epoch  400 : Training loss =  0.075\n",
      "Epoch  450 : Training loss =  0.07083333333333333\n",
      "Test Loss: 0.06666666666666667\n",
      "Test Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.5083333333333333\n",
      "Epoch  50 : Training loss =  0.2875\n",
      "Epoch  100 : Training loss =  0.09166666666666666\n",
      "Epoch  150 : Training loss =  0.05416666666666667\n",
      "Epoch  200 : Training loss =  0.016666666666666666\n",
      "Epoch  250 : Training loss =  0.008333333333333333\n",
      "Epoch  300 : Training loss =  0.0\n",
      "Epoch  350 : Training loss =  0.0\n",
      "Epoch  400 : Training loss =  0.0\n",
      "Epoch  450 : Training loss =  0.0\n",
      "Test Loss: 0.05\n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.05\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.5166666666666667\n",
      "Epoch  50 : Training loss =  0.30416666666666664\n",
      "Epoch  100 : Training loss =  0.25833333333333336\n",
      "Epoch  150 : Training loss =  0.0125\n",
      "Epoch  200 : Training loss =  0.0\n",
      "Epoch  250 : Training loss =  0.0\n",
      "Epoch  300 : Training loss =  0.0\n",
      "Epoch  350 : Training loss =  0.0\n",
      "Epoch  400 : Training loss =  0.0\n",
      "Epoch  450 : Training loss =  0.0\n",
      "Test Loss: 0.03333333333333333\n",
      "Test Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.1\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.4625\n",
      "Epoch  50 : Training loss =  0.475\n",
      "Epoch  100 : Training loss =  0.029166666666666667\n",
      "Epoch  150 : Training loss =  0.0\n",
      "Epoch  200 : Training loss =  0.0\n",
      "Epoch  250 : Training loss =  0.0\n",
      "Epoch  300 : Training loss =  0.0\n",
      "Epoch  350 : Training loss =  0.0\n",
      "Epoch  400 : Training loss =  0.0\n",
      "Epoch  450 : Training loss =  0.0\n",
      "Test Loss: 0.03333333333333333\n",
      "Test Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.5\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.48333333333333334\n",
      "Epoch  50 : Training loss =  0.3541666666666667\n",
      "Epoch  100 : Training loss =  0.0\n",
      "Epoch  150 : Training loss =  0.0\n",
      "Epoch  200 : Training loss =  0.0\n",
      "Epoch  250 : Training loss =  0.0\n",
      "Epoch  300 : Training loss =  0.0\n",
      "Epoch  350 : Training loss =  0.0\n",
      "Epoch  400 : Training loss =  0.0\n",
      "Epoch  450 : Training loss =  0.0\n",
      "Test Loss: 0.05\n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 1\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.5166666666666667\n",
      "Epoch  50 : Training loss =  0.2\n",
      "Epoch  100 : Training loss =  0.0\n",
      "Epoch  150 : Training loss =  0.0\n",
      "Epoch  200 : Training loss =  0.0\n",
      "Epoch  250 : Training loss =  0.0\n",
      "Epoch  300 : Training loss =  0.0\n",
      "Epoch  350 : Training loss =  0.0\n",
      "Epoch  400 : Training loss =  0.0\n",
      "Epoch  450 : Training loss =  0.0\n",
      "Test Loss: 0.13333333333333333\n",
      "Test Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 5\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.5166666666666667\n",
      "Epoch  50 : Training loss =  0.3125\n",
      "Epoch  100 : Training loss =  0.0\n",
      "Epoch  150 : Training loss =  0.0\n",
      "Epoch  200 : Training loss =  0.0\n",
      "Epoch  250 : Training loss =  0.0\n",
      "Epoch  300 : Training loss =  0.0\n",
      "Epoch  350 : Training loss =  0.0\n",
      "Epoch  400 : Training loss =  0.0\n",
      "Epoch  450 : Training loss =  0.0\n",
      "Test Loss: 0.23333333333333334\n",
      "Test Accuracy: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "learning_rate = 10\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concolusion ####\n",
    "As the learning_rate increases, the speed of weight change increases and MSE approaches zero at a higher rate. Seeing the number of the Epochs also confirms our claim. But by increasing the size too much, we will see that the fitness on the test data decreases, and this indicates the overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Training loss =  0.4791666666666667\n",
      "Epoch  50 : Training loss =  0.44583333333333336\n",
      "Epoch  100 : Training loss =  0.0\n",
      "Epoch  150 : Training loss =  0.0\n",
      "Epoch  200 : Training loss =  0.0\n",
      "Epoch  250 : Training loss =  0.0\n",
      "Epoch  300 : Training loss =  0.0\n",
      "Epoch  350 : Training loss =  0.0\n",
      "Epoch  400 : Training loss =  0.0\n",
      "Epoch  450 : Training loss =  0.0\n",
      "Epoch  500 : Training loss =  0.0\n",
      "Epoch  550 : Training loss =  0.0\n",
      "Epoch  600 : Training loss =  0.0\n",
      "Epoch  650 : Training loss =  0.0\n",
      "Epoch  700 : Training loss =  0.0\n",
      "Epoch  750 : Training loss =  0.0\n",
      "Epoch  800 : Training loss =  0.0\n",
      "Epoch  850 : Training loss =  0.0\n",
      "Epoch  900 : Training loss =  0.0\n",
      "Epoch  950 : Training loss =  0.0\n",
      "Test Loss: 0.05\n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 1\n",
    "\n",
    "weights1, b1, weights2, b2 = Train(X_train, y_train, 1000, learning_rate, epochs)\n",
    "\n",
    "Y_pred = Predict(X_test, weights1, b1, weights2, b2)\n",
    "test_loss = MSE(y_test, Y_pred.T)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "accuracy = np.mean(Y_pred.T == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
